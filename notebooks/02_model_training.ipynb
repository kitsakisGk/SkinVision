{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — Model Training\n",
    "\n",
    "In this notebook we:\n",
    "1. Load HAM10000 with our custom PyTorch Dataset\n",
    "2. Apply data augmentation (albumentations)\n",
    "3. Fine-tune **EfficientNet-B0** using transfer learning\n",
    "4. Handle class imbalance with weighted loss\n",
    "5. Train with early stopping and save the best model\n",
    "\n",
    "> Training on **CPU** — using 128x128 images and a lightweight model to keep it manageable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from src.config import (\n",
    "    DATA_DIR, MODELS_DIR, RESULTS_DIR, SEED,\n",
    "    CLASS_NAMES, CLASS_LABELS, NUM_CLASSES,\n",
    "    IMAGE_SIZE, BATCH_SIZE, LEARNING_RATE, NUM_EPOCHS,\n",
    "    MODEL_NAME, EARLY_STOPPING_PATIENCE,\n",
    ")\n",
    "\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'Device: {\"cuda\" if torch.cuda.is_available() else \"cpu\"}')\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Image size: {IMAGE_SIZE}x{IMAGE_SIZE}')\n",
    "print(f'Batch size: {BATCH_SIZE}')\n",
    "print(f'Epochs: {NUM_EPOCHS}')\n",
    "print(f'Learning rate: {LEARNING_RATE}')\n",
    "print()\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Prepare the Data\n",
    "\n",
    "We need to do three things before training:\n",
    "\n",
    "1. **Find all images** — HAM10000 splits images across two folders (`part_1` and `part_2`), so we build a lookup dictionary to find any image by its ID.\n",
    "\n",
    "2. **Split the data** — We split into 70% train / 15% validation / 15% test, using **stratified splitting** (ensures each split has the same proportion of each skin condition).\n",
    "\n",
    "3. **Handle class imbalance** — Since Melanocytic Nevus is 67% of the data, we compute **class weights** so the model pays more attention to rare conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images are split across two folders — let's find them all\n",
    "image_dirs = [\n",
    "    DATA_DIR / 'HAM10000_images_part_1',\n",
    "    DATA_DIR / 'HAM10000_images_part_2',\n",
    "]\n",
    "\n",
    "# Load the metadata CSV (contains image_id, diagnosis, age, sex, etc.)\n",
    "metadata_path = DATA_DIR / 'HAM10000_metadata.csv'\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Count images across both folders\n",
    "total_images = sum(\n",
    "    len([f for f in d.iterdir() if f.suffix == '.jpg'])\n",
    "    for d in image_dirs if d.exists()\n",
    ")\n",
    "\n",
    "print(f'Found {total_images} images')\n",
    "print(f'Metadata rows: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Train / Val / Test Split\n",
    "\n",
    "**Why stratified?** If we split randomly, rare classes like Dermatofibroma (1.1%) might end up with 0 samples in the test set. Stratified splitting guarantees each class keeps its proportion in every split.\n",
    "\n",
    "**Why 70/15/15?**\n",
    "- **Train (70%)** — the model learns from these images\n",
    "- **Validation (15%)** — we check performance after each epoch to detect overfitting\n",
    "- **Test (15%)** — final evaluation on data the model has never seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.dataset import HAM10000Dataset, get_transforms\n",
    "\n",
    "# Stratified split: 70% train, 15% val, 15% test\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df, test_size=0.15, stratify=df['dx'], random_state=SEED\n",
    ")\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, test_size=0.176, stratify=train_val_df['dx'], random_state=SEED\n",
    "    # 0.176 of 85% = 15% of total\n",
    ")\n",
    "\n",
    "print(f'Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)')\n",
    "print(f'Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)')\n",
    "print(f'Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)')\n",
    "print()\n",
    "\n",
    "# Verify stratification — percentages should be similar across all splits\n",
    "print('Class distribution check (should be similar across splits):')\n",
    "for cls in CLASS_NAMES:\n",
    "    tr = (train_df['dx'] == cls).sum() / len(train_df) * 100\n",
    "    va = (val_df['dx'] == cls).sum() / len(val_df) * 100\n",
    "    te = (test_df['dx'] == cls).sum() / len(test_df) * 100\n",
    "    print(f'  {CLASS_LABELS[cls]:30s}  train:{tr:5.1f}%  val:{va:5.1f}%  test:{te:5.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PyTorch Datasets and DataLoaders\n",
    "\n",
    "Our custom `HAM10000Dataset` class does three things:\n",
    "1. **Loads an image** from disk by its ID\n",
    "2. **Applies augmentation** (only for training — flips, rotations, color changes)\n",
    "3. **Returns a tensor** (numbers the model can process) + the label (which condition it is)\n",
    "\n",
    "A **DataLoader** wraps the dataset and feeds images to the model in batches of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create datasets — training gets augmentation, val/test don't\n",
    "train_dataset = HAM10000Dataset(train_df, image_dirs=image_dirs, transform=get_transforms('train'))\n",
    "val_dataset = HAM10000Dataset(val_df, image_dirs=image_dirs, transform=get_transforms('val'))\n",
    "test_dataset = HAM10000Dataset(test_df, image_dirs=image_dirs, transform=get_transforms('test'))\n",
    "\n",
    "# Create dataloaders (feeds batches of 16 images to the model)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Test: grab one batch and check the shapes\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f'Batch shape: {images.shape}')   # [16, 3, 128, 128] = 16 images, 3 color channels, 128x128 pixels\n",
    "print(f'Labels shape: {labels.shape}')  # [16] = one label per image\n",
    "print(f'Label values: {labels.tolist()}')  # Numbers 0-6 representing the 7 conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights for Imbalanced Data\n",
    "\n",
    "Remember from EDA: Melanocytic Nevus is 67% of the data while Dermatofibroma is only 1%.\n",
    "\n",
    "Without weights, the model would just predict \"mole\" for everything and get 67% accuracy.\n",
    "\n",
    "**Class weights** tell the loss function: *\"if you get a rare condition wrong, it counts much more.\"*\n",
    "\n",
    "Formula: `weight = total_samples / (num_classes * class_count)`\n",
    "- Common class (nv, 6705 images) -> low weight (~0.2)\n",
    "- Rare class (df, 115 images) -> high weight (~12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for imbalanced data\n",
    "label_counts = train_df['dx'].value_counts()\n",
    "total = len(train_df)\n",
    "class_weights = torch.tensor(\n",
    "    [total / (NUM_CLASSES * label_counts.get(c, 1)) for c in CLASS_NAMES],\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "print('Class weights (higher = rarer class gets more attention):')\n",
    "for cls, w in zip(CLASS_NAMES, class_weights):\n",
    "    print(f'  {CLASS_LABELS[cls]:30s}: {w:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Augmented Samples\n",
    "\n",
    "Data augmentation creates variations of training images (flips, rotations, color shifts).\n",
    "\n",
    "**Why?** It artificially increases dataset size and teaches the model that a mole is still a mole even if the image is flipped or slightly darker. This prevents overfitting (memorizing training images instead of learning patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import denormalize\n",
    "\n",
    "# Show a few augmented training samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i in range(10):\n",
    "    img, label = train_dataset[i]\n",
    "    img_display = denormalize(img)  # Undo normalization so we can see the actual colors\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(img_display)\n",
    "    ax.set_title(CLASS_NAMES[label], fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Augmented Training Samples (flipped, rotated, color-shifted)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'augmented_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Build the Model\n",
    "\n",
    "### What is Transfer Learning?\n",
    "\n",
    "**EfficientNet-B0** was pre-trained on **ImageNet** (14 million images, 1000 categories like cats, dogs, cars).\n",
    "\n",
    "It already knows how to see edges, textures, shapes, and colors. We don't need to teach it that from scratch — we just need to teach it *our specific task*: \"which of these 7 skin conditions is this?\"\n",
    "\n",
    "### Two-Phase Training Strategy:\n",
    "\n",
    "1. **Phase 1 — Head only** (fast): Freeze the pretrained layers, only train the new classifier head. This teaches the head to use the existing features for our 7 classes.\n",
    "\n",
    "2. **Phase 2 — Full fine-tuning** (slower): Unfreeze everything and fine-tune with a very small learning rate. This gently adjusts the pretrained features to be even better for skin lesions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import create_model, freeze_base, unfreeze_all, get_model_summary\n",
    "\n",
    "# Create the model — downloads pretrained weights from ImageNet\n",
    "model = create_model(MODEL_NAME, NUM_CLASSES, pretrained=True)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Output classes: {NUM_CLASSES}')\n",
    "print()\n",
    "\n",
    "# Phase 1: Freeze base layers — only the classifier head will train\n",
    "model = freeze_base(model)\n",
    "print('After freezing base:')\n",
    "get_model_summary(model)\n",
    "print()\n",
    "print('Only ~9K parameters will train in Phase 1 (the head).')\n",
    "print('The other 4M parameters stay frozen (pretrained ImageNet features).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Train — Phase 1: Classifier Head Only\n",
    "\n",
    "We train only the last layer (classifier head) for 5 epochs with a **higher learning rate (1e-3)**.\n",
    "\n",
    "This is fast because we're only updating ~9,000 parameters out of 4 million. Think of it as: the model already knows how to see, we're just teaching it what our 7 labels mean.\n",
    "\n",
    "**What to watch for:**\n",
    "- Training loss should drop quickly\n",
    "- Validation accuracy should improve\n",
    "- This phase takes just a few minutes on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import train_model, set_seed\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "print('=== PHASE 1: Training classifier head (base frozen) ===')\n",
    "print('This should be fast even on CPU...\\n')\n",
    "\n",
    "model, history_phase1 = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    class_weights=class_weights,\n",
    "    num_epochs=5,           # Just a few epochs for the head\n",
    "    lr=1e-3,                # Higher LR since only training the head\n",
    "    patience=3,\n",
    "    save_name='phase1_head.pth',\n",
    ")\n",
    "\n",
    "print('\\nPhase 1 complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train — Phase 2: Full Fine-tuning\n",
    "\n",
    "Now we unfreeze ALL layers and train the entire model with a **much lower learning rate (1e-4)**.\n",
    "\n",
    "**Why a lower learning rate?** The pretrained features are already good — we don't want to destroy them with large updates. Small adjustments make the features slightly better for skin lesions specifically.\n",
    "\n",
    "**Early stopping** watches validation loss. If it doesn't improve for 4 epochs in a row, training stops automatically to prevent overfitting.\n",
    "\n",
    "**What to watch for:**\n",
    "- Val accuracy should gradually improve beyond Phase 1\n",
    "- If val loss starts going UP while train loss goes DOWN = overfitting (early stopping catches this)\n",
    "- This phase takes longer (~20-30 min on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all layers for full fine-tuning\n",
    "model = unfreeze_all(model)\n",
    "print('After unfreezing all layers:')\n",
    "get_model_summary(model)\n",
    "\n",
    "print()\n",
    "print('=== PHASE 2: Full fine-tuning ===')\n",
    "print('This will take longer on CPU — grab a coffee...\\n')\n",
    "\n",
    "model, history_phase2 = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    class_weights=class_weights,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    lr=LEARNING_RATE,        # Lower LR for fine-tuning\n",
    "    patience=EARLY_STOPPING_PATIENCE,\n",
    "    save_name='best_model.pth',\n",
    ")\n",
    "\n",
    "print('\\nPhase 2 complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Training Curves\n",
    "\n",
    "These charts show how the model learned over time:\n",
    "\n",
    "- **Loss chart (left)** — should go down for both train and val. If train keeps dropping but val goes up, the model is overfitting.\n",
    "- **Accuracy chart (right)** — should go up. The gap between train and val accuracy tells us about overfitting.\n",
    "\n",
    "The vertical \"jump\" between Phase 1 and Phase 2 is normal — we went from training 9K params to 4M params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine histories from both phases into one timeline\n",
    "history = {\n",
    "    'train_loss': history_phase1['train_loss'] + history_phase2['train_loss'],\n",
    "    'val_loss': history_phase1['val_loss'] + history_phase2['val_loss'],\n",
    "    'train_acc': history_phase1['train_acc'] + history_phase2['train_acc'],\n",
    "    'val_acc': history_phase1['val_acc'] + history_phase2['val_acc'],\n",
    "}\n",
    "\n",
    "from src.evaluate import plot_training_history\n",
    "\n",
    "plot_training_history(history, save=True)\n",
    "print(f'\\nBest val accuracy: {max(history[\"val_acc\"]):.4f} ({max(history[\"val_acc\"])*100:.1f}%)')\n",
    "print(f'Best val loss: {min(history[\"val_loss\"]):.4f}')\n",
    "print(f'Total epochs trained: {len(history[\"train_loss\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Test Set Evaluation\n",
    "\n",
    "Now the real test — how does the model perform on images it has **never seen during training**?\n",
    "\n",
    "The **classification report** shows per-class metrics:\n",
    "- **Precision** — \"When the model says melanoma, how often is it right?\"\n",
    "- **Recall** — \"Of all actual melanomas, how many did the model catch?\"\n",
    "- **F1-score** — The balance between precision and recall\n",
    "\n",
    "For medical applications, **recall is more important than precision** — it's worse to miss a melanoma (false negative) than to flag a mole for review (false positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import get_predictions, print_classification_report\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_true, y_pred, y_probs = get_predictions(model, test_loader, device)\n",
    "\n",
    "print('=== TEST SET RESULTS ===')\n",
    "print()\n",
    "print_classification_report(y_true, y_pred)\n",
    "\n",
    "# Overall accuracy\n",
    "accuracy = (y_true == y_pred).mean()\n",
    "print(f'\\nOverall test accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "The confusion matrix shows exactly where the model gets confused.\n",
    "\n",
    "- **Diagonal** (top-left to bottom-right) = correct predictions\n",
    "- **Off-diagonal** = mistakes\n",
    "- For example, if the model often confuses Melanoma with Melanocytic Nevus, you'll see a high number in that cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a JSON file for the README and future reference\n",
    "import json\n",
    "\n",
    "test_results = {\n",
    "    'accuracy': float(accuracy),\n",
    "    'best_val_loss': float(min(history['val_loss'])),\n",
    "    'best_val_acc': float(max(history['val_acc'])),\n",
    "    'total_epochs': len(history['train_loss']),\n",
    "    'model': MODEL_NAME,\n",
    "    'image_size': IMAGE_SIZE,\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'training_results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print('Results saved to results/training_results.json')\n",
    "print(json.dumps(test_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### What we did:\n",
    "1. **Loaded** 10,015 images with stratified 70/15/15 split\n",
    "2. **Augmented** training data (flips, rotations, color jitter) to prevent overfitting\n",
    "3. **Weighted** the loss function so rare conditions get more attention\n",
    "4. **Phase 1**: Trained only the classifier head (base frozen) — fast warm-up\n",
    "5. **Phase 2**: Fine-tuned entire model with lower learning rate — full optimization\n",
    "6. **Early stopping** saved the best model automatically\n",
    "\n",
    "### Key concepts learned:\n",
    "- **Transfer learning** — reusing knowledge from ImageNet instead of training from scratch\n",
    "- **Two-phase training** — head first, then fine-tune all\n",
    "- **Class imbalance handling** — weighted loss function\n",
    "- **Early stopping** — prevents overfitting by stopping when validation loss stops improving\n",
    "- **Stratified splitting** — preserves class proportions in train/val/test\n",
    "\n",
    "### Saved files:\n",
    "- `models/best_model.pth` — best model weights\n",
    "- `results/training_curves.png` — loss and accuracy plots\n",
    "- `results/confusion_matrix.png` — test set confusion matrix\n",
    "- `results/training_results.json` — metrics summary\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "-> **03_evaluation.ipynb** — deeper evaluation with ROC curves and per-class analysis\n",
    "\n",
    "-> **04_gradcam.ipynb** — visualize which regions of the image the model focuses on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
